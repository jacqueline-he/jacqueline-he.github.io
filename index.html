<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jacqueline He</title>
  
  <meta name="author" content="Jacqueline He">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŒ±</text></svg>">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-JDY1XTPZQ6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-JDY1XTPZQ6');
  </script>
  <script type="text/javascript">
    function showAbstract(abstract)
    {
    	var x = document.getElementById(abstract);
    	if (x.style.display === "none") {
      		x.style.display = "inline-block";
    	}
    	else {
      		x.style.display = "none";
    	}
    }
    
    </script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jacqueline He</name>
              </p>
              <p>I am currently a software engineer at <a href="https://about.facebook.com/">Meta</a>. </p>
              <p> In 2022, I graduated <i>summa cum laude</i> from <a href="https://princeton.edu/">Princeton University</a> with a BSE in <a href="https://cs.princeton.edu/">Computer Science</a>, and minors in <a href="https://bcf.princeton.edu">Finance</a> and <a href="https://csml.princeton.edu/">Statistics & Machine Learning</a>. 
                I grew up in San Jose, California. </p>
              </p>
              <p style="text-align:center">
                <a href="mailto:jh70@alumni.princeton.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=krTnRRUAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://linkedin.com/in/jacqueline-he">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/jacqueline-he/">Github</a>
              </p>
            </td>
            <!--
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JonBarron_circle.jpg" class="hoverZoomLink"></a>
            </td>
            -->
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am broadly interested in deep learning and natural language processing, specifically the emergent capabilities, applications, and risks of large language models. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <papertitle>Can Rationalization Improve Robustness?</papertitle>
            <br>
            Howard Chen, <strong>Jacqueline He</strong>, Karthik Narasimhan, Danqi Chen
            <br>
            <em>NAACL</em> 2022  
            <br>
            <a id="sample_text" onClick="showAbstract('abs-rationale')">abstract</a> /
            <a href="https://aclanthology.org/2022.naacl-main.278/">paper</a> / 
            <a href="https://github.com/princeton-nlp/rationale-robustness">code</a>  
            <br>	
            <div id="abs-rationale" style="display:none; border-style:dotted; padding:10px;  margin-top: 10px; border-color: #8fa19c">A growing line of work has investigated the development of neural NLP models that can produce rationales--subsets of input that can explain their model predictions. In this paper, we ask whether such rationale models can also provide robustness to adversarial attacks in addition to their interpretable nature. Since these models need to first generate rationales ("rationalizer") before making predictions ("predictor"), they have the potential to ignore noise or adversarially added text by simply masking it out of the generated rationale. To this end, we systematically generate various types of 'AddText' attacks for both token and sentence-level rationalization tasks, and perform an extensive empirical evaluation of state-of-the-art rationale models across five different tasks. Our experiments reveal that the rationale models show the promise to improve robustness, while they struggle in certain scenarios--when the rationalizer is sensitive to positional bias or lexical choices of attack text. Further, leveraging human rationale as supervision does not always translate to better performance. Our study is a first step towards exploring the interplay between interpretability and robustness in the rationalize-then-predict framework.</div>
          </td>

        </tbody>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;"> This page was adapted from <a href="https://jonbarron.info/">Jon Barron's</a> template. </p>
            </td>
          </tr>
        </tbody></table>
        
      </td>
    </tr>
  </table>

</body>

</html>
